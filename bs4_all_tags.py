# -*- coding: utf-8 -*-
"""BS4_all_tags.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QwWuyGEXtBK7CimKitn3YVEV5jrDa9_C
"""

import requests
from bs4 import BeautifulSoup

# Define the URL of the website you want to scrape
url = "#URL"  # Replace with the actual URL

# Send an HTTP request to the URL and get the HTML content
response = requests.get(url)
html_content = response.text

# Create a BeautifulSoup object to parse the HTML
soup = BeautifulSoup(html_content, 'html.parser')

# Find the elements that contain the data you want to scrape
article_elements = soup.find_all('article')  # Assuming articles are contained in <article> tags

# Initialize lists to store the scraped data
titles = []
links = []

# Loop through the article elements and extract data
for article in article_elements:
    title_element = article.find('h2')  # Assuming the title is within an <h2> tag
    link_element = title_element.find('a')  # Assuming the title is linked

    if title_element and link_element:
        title = title_element.text.strip()
        link = link_element['href']  # Get the 'href' attribute of the <a> tag

        titles.append(title)
        links.append(link)

# Print the scraped data
for i in range(len(titles)):
    print(f"Title: {titles[i]}")
    print(f"Link: {links[i]}")
    print()

# You can further process and analyze the data as needed for your data science project.